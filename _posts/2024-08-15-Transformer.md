---
layout: post
title:  "Transformer"
date:   2024-08-15 09:00:00
categories: seq2seq deep-learning
tags: transformer
excerpt: This post discusses the transformer.
mathjax: true
use_mermaid: true
---

* content
{:toc}

# Self-attention

![self-attention](/assets/images/sequence_model/001/self-attention-andrew.png)

![self-attention2](/assets/images/sequence_model/001/self-attention.png)

# References
- Transformer by Hung-yi Lee [Lecture](https://www.youtube.com/watch?v=n9TlOhRjYoc)
- ML 2021 Spring by Hung-yi Lee [Home page](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php)